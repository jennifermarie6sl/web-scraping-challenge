{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4a7025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: crayons in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (0.4.0)\n",
      "Requirement already satisfied: configparser in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (5.0.2)\n",
      "Requirement already satisfied: requests in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (2.25.1)\n",
      "Requirement already satisfied: colorama in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (from crayons->webdriver_manager) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jenniferrocha/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51112573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [/Users/jenniferrocha/.wdm/drivers/chromedriver/mac64/94.0.4606.41/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "078d25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser \n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import requests\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "\n",
    "# /usr/local/bin/chromedriver\n",
    "# Users/jenniferrocha/Desktop/UC_DAVIS/web_scraping_challenge/chromedriver\n",
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {'Users/jenniferrocha/Desktop/UC_DAVIS/web_scraping_challenge/chromedriver': ChromeDriverManager().install()}\n",
    "    return Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# def scrape_info():\n",
    "#     browser = init_browser()\n",
    "\n",
    "#     # Visit Mars site\n",
    "#     url = \"https://mars.nasa.gov/news\"\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Scrape page into Soup\n",
    "#     html = browser.html\n",
    "#     soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#     article = soup.find('div', class_= \"list_text\").text\n",
    "#     news_title = article.find('div', class_=\"content_title\").text\n",
    "#     news_p = article.find('div', class_=\"article_teaser_body\").text\n",
    "    \n",
    "#     news_article = {\n",
    "#         \"news article title\": news_title,\n",
    "#         \"news article content\": news_p\n",
    "#     }\n",
    "\n",
    "#     print(news_article)\n",
    "    \n",
    "#     time.sleep(1)\n",
    "\n",
    "#     # Visit JPL to get image\n",
    "#     jpl_url = (\n",
    "#         \"https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html\"\n",
    "#     )\n",
    "#     browser.visit(jpl_url)\n",
    "\n",
    "#     # Scrape page into Soup\n",
    "#     image_html = browser.html\n",
    "#     image_soup = BeautifulSoup(image_html, \"html.parser\")\n",
    "    \n",
    "#     image = image_soup.find('img', class_= 'headerimage fade-in')['src']\n",
    "#     featured_image_url = \"https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/image/featured/mars3.jpg\"\n",
    "#     print(featured_image_url)\n",
    "\n",
    "#     # Visit Mars Facts to get facts\n",
    "#     facts_url = (\n",
    "#         \"https://space-facts.com/mars/\"\n",
    "#     )\n",
    "#     browser.visit(facts_url)\n",
    "    \n",
    "#     # Scrape page into Soup\n",
    "#     page = requests.get(facts_url)\n",
    "#     facts_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "#     dfs = pd.read_html(page.text)\n",
    "\n",
    "#     table = soup.find_all('table')[4]\n",
    "#     for child in soup.find_all('table')[4].children:\n",
    "#         for td in child:\n",
    "#             print(td.text)\n",
    "# #         I think table is tbody with the lines being tr\n",
    "\n",
    "#     # Close the browser after scraping\n",
    "#     browser.quit()\n",
    "    \n",
    "#     # Visit Mars Facts to get facts\n",
    "#     hem_url = (\n",
    "#         \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "#     )\n",
    "#     browser.visit(hem_url)\n",
    "    \n",
    "#     # Scrape page into Soup\n",
    "# #     page = requests.get(hem_url)\n",
    "# #     facts_soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836c2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91caf6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94a994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f924b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/a-guide-to-scraping-html-tables-with-pandas-and-beautifulsoup-7fc24c331cf7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e476a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f190edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obtain high resolution images for each of Marâ€™s hemispheres.\n",
    "\n",
    "You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "\n",
    "Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6373018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
